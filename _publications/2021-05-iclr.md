---
title: 'How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision'
authors: 'Dongkwan Kim and Alice Oh'
collection: 'publications'
permalink: '/publications/2021-05-iclr'
date: '2021-05-03'
venue: 'International Conference on Learning Representations (ICLR)'
type: 'conference'
summary: '*One-sentence Summary: We propose a method that self-supervise graph attention through edges and it should be designed according to the average degree and homophily of graphs.*'
venueurl: 'https://iclr.cc/Conferences/2021'
paperurl: 'https://openreview.net/forum?id=Wi5KUNlqWty'
arxivurl: 'https://arxiv.org/abs/2204.04879'
codeurl: 'https://github.com/dongkwan-kim/SuperGAT'
slideurl: 'https://docs.google.com/presentation/d/e/2PACX-1vR3huzPPvgb9ERiXN8LtTR70FY2nhkIKS_pO4z0_flpMXUfbcY-gW4O6gCeDiY1FQ044UbJf69AF1cR/pub?slide=id.p'
---

Attention mechanism in graph neural networks is designed to assign larger weights to important neighbor nodes for better representation. However, what graph attention learns is not understood well, particularly when graphs are noisy. In this paper, we propose a self-supervised graph attention network (SuperGAT), an improved graph attention model for noisy graphs. Specifically, we exploit two attention forms compatible with a self-supervised task to predict edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. By encoding edges, SuperGAT learns more expressive attention in distinguishing mislinked neighbors. We find two graph characteristics influence the effectiveness of attention forms and self-supervision: homophily and average degree. Thus, our recipe provides guidance on which attention design to use when those two graph characteristics are known. Our experiment on 17 real-world datasets demonstrates that our recipe generalizes across 15 datasets of them, and our models designed by recipe show improved performance over baselines.